<!DOCTYPE html>
<html>
  <head>
    <title>Ruiquan Huang's Personal Website</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        background-color: #f4f4f4;
        color: #333;
        margin: 0;
        padding: 0;
      }
      .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
      }
      .blurb {
        padding: 20px;
        background: #fff;
        margin-top: 20px;
        border-radius: 5px;
      }
      ul {
      list-style-type: disc; /* Default bullet points */
      padding-left: 20px; /* Adds padding to the left for indentation */
      }
      li {
        margin-bottom: 10px; /* Adds space below each list item */
      }
      footer {
        text-align: center;
        padding: 10px;
        background: #333;
        color: #fff;
        position: fixed;
        width: 100%;
        bottom: 0;
      }
      footer ul {
        list-style: none;
        padding: 0;
      }
      footer li {
        display: inline;
        margin: 0 10px;
      }
      footer a {
        color: #fff;
        text-decoration: none;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="blurb">
        <h1>About Me</h1>
        
        <p>Hi there, my name is Ruiquan Huang. I am a PhD candidate at <a href="https://www.psu.edu" target="_blank">The Pennsylvania State University</a> and am fortunate to be adivsed by Professor <a href="https://www.ee.psu.edu/yang/index.html" target="_blank">Jing Yang</a>.</p>

        <p>My research focuses on reinforcement learning, transformer theory, safety and privacy issues in learning problems.</p>

        <ul>
          <li>Email: <a href="mailto:rzh5514@psu.edu">rzh 55 14 at psu dot edu</a></li> 
          <li><a href="https://scholar.google.com/citations?user=0eo3JGgAAAAJ&hl=en" target="_blank">Google Scholar Profile</a></li>
        </ul>
        
        

        <h1>Selected Publications</h1>
        <ul>
          <li><a href="https://arxiv.org/abs/2307.00405" target="_blank"> Provably Efficient UCB-type Algorithms For Learning Predictive State Representations, ICLR 2024.</a></li>
          
          <li><a href="https://arxiv.org/abs/2206.14057" target="_blank"> Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-free RL, ICLR 2023.</a></li>
          
          <li><a href="https://proceedings.mlr.press/v202/huang23q.html" target="_blank"> Federated Linear Contextual Bandits with User-level Differential Privacy, ICML 2023.</a></li>
          
          <li><a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/e347c51419ffb23ca3fd5050202f9c3d-Abstract.html" target="_blank"> Federated Linear Contextual Bandits, Neurips 2021.</a></li>
        </ul>
        </div>
      </div>
    <footer>
      
    </footer>
  </body>
</html>
